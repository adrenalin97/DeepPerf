{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run on TensorFlow 2.x\n",
    "%tensorflow_version 2.x\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import relevant modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from mlp_sparse_model import MLPSparseModel\n",
    "from mlp_plain_model import MLPPlainModel\n",
    "import time\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.7f}\".format\n",
    "\n",
    "# The following line improves formatting when ouputting NumPy arrays.\n",
    "np.set_printoptions(linewidth = 200)\n",
    "\n",
    "SAMPLE_SIZE = 11\n",
    "N_EXP = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_generator():\n",
    "    # Generate the initial seed for each sample size (to match the seed\n",
    "    # of the results in the paper)\n",
    "    # This is just the initial seed, for each experiment, the seeds will be\n",
    "    # equal the initial seed + the number of the experiment\n",
    "\n",
    "    N_train_all = np.multiply(11, [1, 2, 3, 4, 5])  # This is for LLVM\n",
    "    if SAMPLE_SIZE in N_train_all:\n",
    "        seed_o = np.where(N_train_all == SAMPLE_SIZE)[0][0]\n",
    "    else:\n",
    "        seed_o = np.random.randint(1, 101)\n",
    "\n",
    "    return seed_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Get data\n",
    "data_df = pd.read_csv(\"Data/LLVM_AllNumeric.csv\")\n",
    "column_dict = {name: bool for name in list(data_df.columns.values) if name != 'PERF'}\n",
    "column_dict['PERF'] = \"float64\"\n",
    "data_df = data_df.astype(column_dict)\n",
    "data_df = data_df.reindex(np.random.permutation(data_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values\n",
    "data_df_mean = data_df.mean()\n",
    "data_df_std = data_df.std()\n",
    "data_df_norm = (data_df - data_df_mean)/data_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set and set seed\n",
    "seed_init = seed_generator()\n",
    "seed = seed_init*N_EXP + 1\n",
    "np.random.seed(seed_init)\n",
    "train_df = data_df_norm.sample(frac=0.6)\n",
    "test_df = data_df_norm.drop(train_df.index).sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature layer\n",
    "columns = [column for column in column_dict.keys() if column != 'PERF']\n",
    "feature_columns = []\n",
    "for column in columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(column))\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the plotting function.\n",
    "\n",
    "def plot_the_loss_curve(epochs, mse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs, mse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Double-click for a possible solution\n",
    "\n",
    "# The following \"solution\" uses L2 regularization to bring training loss\n",
    "# and test loss closer to each other. Many, many other solutions are possible.\n",
    "\n",
    "\n",
    "def create_model(learning_rate, feature_layer):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "\n",
    "  # Discard any pre-existing version of the model.\n",
    "  model = None\n",
    "\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Add the layer containing the feature columns to the model.\n",
    "  model.add(feature_layer)\n",
    "\n",
    "  # Describe the topography of the model. \n",
    "\n",
    "  # Implement L2 regularization in the first hidden layer.\n",
    "  model.add(tf.keras.layers.Dense(units=20, \n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l1(0.007),\n",
    "                                  name='Hidden1'))\n",
    "  \n",
    "  # Implement L2 regularization in the second hidden layer.\n",
    "  model.add(tf.keras.layers.Dense(units=12, \n",
    "                                  activation='relu', \n",
    "                                  kernel_regularizer=tf.keras.regularizers.l1(0.007),\n",
    "                                  name='Hidden2'))\n",
    "\n",
    "  # Define the output layer.\n",
    "  model.add(tf.keras.layers.Dense(units=1,  \n",
    "                                  name='Output'))                              \n",
    "  \n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "  return model     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, epochs, label_name,\n",
    "                batch_size=None, validation_split=0.1):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  # Split the dataset into features and label.\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name))\n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, validation_split=validation_split) \n",
    "\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "  \n",
    "  # To track the progression of training, gather a snapshot\n",
    "  # of the model's mean squared error at each epoch. \n",
    "  hist = pd.DataFrame(history.history)\n",
    "  mse = hist[\"mean_squared_error\"]\n",
    "\n",
    "  return epochs, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'gvn': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'instcombine': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'inline': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'jump_threading': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'simplifycfg': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'sccp': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'print_used_types': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ipsccp': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'iv_users': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'licm': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'gvn': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'instcombine': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'inline': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'jump_threading': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'simplifycfg': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'sccp': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'print_used_types': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ipsccp': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'iv_users': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'licm': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.7603 - mean_squared_error: 0.6651WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'gvn': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>, 'instcombine': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'inline': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'jump_threading': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'simplifycfg': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'sccp': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'print_used_types': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ipsccp': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'iv_users': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'licm': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "56/56 [==============================] - 1s 8ms/step - loss: 0.7603 - mean_squared_error: 0.6651 - val_loss: 0.3532 - val_mean_squared_error: 0.2582\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.2889 - mean_squared_error: 0.1956 - val_loss: 0.2279 - val_mean_squared_error: 0.1367\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.2113 - mean_squared_error: 0.1223 - val_loss: 0.1851 - val_mean_squared_error: 0.0989\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1713 - mean_squared_error: 0.0876 - val_loss: 0.1653 - val_mean_squared_error: 0.0839\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1577 - mean_squared_error: 0.0787 - val_loss: 0.1511 - val_mean_squared_error: 0.0746\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1436 - mean_squared_error: 0.0687 - val_loss: 0.1553 - val_mean_squared_error: 0.0825\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1400 - mean_squared_error: 0.0688 - val_loss: 0.1414 - val_mean_squared_error: 0.0722\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1395 - mean_squared_error: 0.0717 - val_loss: 0.1474 - val_mean_squared_error: 0.0811\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1269 - mean_squared_error: 0.0618 - val_loss: 0.1446 - val_mean_squared_error: 0.0811\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.1270 - mean_squared_error: 0.0648 - val_loss: 0.1485 - val_mean_squared_error: 0.0878\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1249 - mean_squared_error: 0.0652 - val_loss: 0.1337 - val_mean_squared_error: 0.0751\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1191 - mean_squared_error: 0.0621 - val_loss: 0.1359 - val_mean_squared_error: 0.0797\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1139 - mean_squared_error: 0.0587 - val_loss: 0.1217 - val_mean_squared_error: 0.0674\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1182 - mean_squared_error: 0.0650 - val_loss: 0.1324 - val_mean_squared_error: 0.0802\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.1219 - mean_squared_error: 0.0698 - val_loss: 0.1307 - val_mean_squared_error: 0.0797\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.1089 - mean_squared_error: 0.0587 - val_loss: 0.1145 - val_mean_squared_error: 0.0649\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1081 - mean_squared_error: 0.0591 - val_loss: 0.1140 - val_mean_squared_error: 0.0662\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1069 - mean_squared_error: 0.0599 - val_loss: 0.1192 - val_mean_squared_error: 0.0733\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1048 - mean_squared_error: 0.0588 - val_loss: 0.1246 - val_mean_squared_error: 0.0792\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1013 - mean_squared_error: 0.0560 - val_loss: 0.1016 - val_mean_squared_error: 0.0569\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.1060 - mean_squared_error: 0.0617 - val_loss: 0.1123 - val_mean_squared_error: 0.0682\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1005 - mean_squared_error: 0.0574 - val_loss: 0.1243 - val_mean_squared_error: 0.0821\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1064 - mean_squared_error: 0.0636 - val_loss: 0.1114 - val_mean_squared_error: 0.0693\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1081 - mean_squared_error: 0.0656 - val_loss: 0.1091 - val_mean_squared_error: 0.0677\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0990 - mean_squared_error: 0.0579 - val_loss: 0.1024 - val_mean_squared_error: 0.0619\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0982 - mean_squared_error: 0.0579 - val_loss: 0.1047 - val_mean_squared_error: 0.0649\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0966 - mean_squared_error: 0.0567 - val_loss: 0.1068 - val_mean_squared_error: 0.0670\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0939 - mean_squared_error: 0.0540 - val_loss: 0.1220 - val_mean_squared_error: 0.0821\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0960 - mean_squared_error: 0.0568 - val_loss: 0.1079 - val_mean_squared_error: 0.0690\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1023 - mean_squared_error: 0.0630 - val_loss: 0.0947 - val_mean_squared_error: 0.0559\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0992 - mean_squared_error: 0.0603 - val_loss: 0.1335 - val_mean_squared_error: 0.0948\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1022 - mean_squared_error: 0.0642 - val_loss: 0.1141 - val_mean_squared_error: 0.0764\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0899 - mean_squared_error: 0.0524 - val_loss: 0.0936 - val_mean_squared_error: 0.0565\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0943 - mean_squared_error: 0.0574 - val_loss: 0.1011 - val_mean_squared_error: 0.0646\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0948 - mean_squared_error: 0.0585 - val_loss: 0.1025 - val_mean_squared_error: 0.0658\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0887 - mean_squared_error: 0.0526 - val_loss: 0.1062 - val_mean_squared_error: 0.0700\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0862 - mean_squared_error: 0.0503 - val_loss: 0.1016 - val_mean_squared_error: 0.0663\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0880 - mean_squared_error: 0.0529 - val_loss: 0.0906 - val_mean_squared_error: 0.0561\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1041 - mean_squared_error: 0.0690 - val_loss: 0.1012 - val_mean_squared_error: 0.0665\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0947 - mean_squared_error: 0.0599 - val_loss: 0.1166 - val_mean_squared_error: 0.0817\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1077 - mean_squared_error: 0.0711 - val_loss: 0.1113 - val_mean_squared_error: 0.0746\n",
      "Epoch 42/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0921 - mean_squared_error: 0.0565 - val_loss: 0.1044 - val_mean_squared_error: 0.0694\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0861 - mean_squared_error: 0.0517 - val_loss: 0.0917 - val_mean_squared_error: 0.0577\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0810 - mean_squared_error: 0.0476 - val_loss: 0.0992 - val_mean_squared_error: 0.0658\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0819 - mean_squared_error: 0.0486 - val_loss: 0.0844 - val_mean_squared_error: 0.0512\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0801 - mean_squared_error: 0.0476 - val_loss: 0.1055 - val_mean_squared_error: 0.0732\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0831 - mean_squared_error: 0.0504 - val_loss: 0.0870 - val_mean_squared_error: 0.0546\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0807 - mean_squared_error: 0.0485 - val_loss: 0.0926 - val_mean_squared_error: 0.0602\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0804 - mean_squared_error: 0.0487 - val_loss: 0.1163 - val_mean_squared_error: 0.0847\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.1304 - mean_squared_error: 0.0966 - val_loss: 0.1007 - val_mean_squared_error: 0.0666\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0910 - mean_squared_error: 0.0571 - val_loss: 0.0993 - val_mean_squared_error: 0.0662\n",
      "Epoch 52/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0800 - mean_squared_error: 0.0473 - val_loss: 0.1013 - val_mean_squared_error: 0.0688\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0790 - mean_squared_error: 0.0467 - val_loss: 0.1153 - val_mean_squared_error: 0.0833\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0803 - mean_squared_error: 0.0482 - val_loss: 0.1062 - val_mean_squared_error: 0.0741\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0779 - mean_squared_error: 0.0461 - val_loss: 0.1089 - val_mean_squared_error: 0.0771\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0760 - mean_squared_error: 0.0446 - val_loss: 0.1029 - val_mean_squared_error: 0.0716\n",
      "Epoch 57/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0761 - mean_squared_error: 0.0449 - val_loss: 0.1059 - val_mean_squared_error: 0.0744\n",
      "Epoch 58/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0753 - mean_squared_error: 0.0442 - val_loss: 0.0896 - val_mean_squared_error: 0.0587\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0779 - mean_squared_error: 0.0467 - val_loss: 0.0897 - val_mean_squared_error: 0.0586\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0761 - mean_squared_error: 0.0451 - val_loss: 0.0933 - val_mean_squared_error: 0.0628\n",
      "Epoch 61/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0751 - mean_squared_error: 0.0448 - val_loss: 0.0834 - val_mean_squared_error: 0.0534\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0773 - mean_squared_error: 0.0469 - val_loss: 0.0929 - val_mean_squared_error: 0.0630\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0745 - mean_squared_error: 0.0442 - val_loss: 0.0903 - val_mean_squared_error: 0.0598\n",
      "Epoch 64/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0733 - mean_squared_error: 0.0428 - val_loss: 0.0998 - val_mean_squared_error: 0.0696\n",
      "Epoch 65/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0755 - mean_squared_error: 0.0452 - val_loss: 0.0901 - val_mean_squared_error: 0.0598\n",
      "Epoch 66/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0741 - mean_squared_error: 0.0437 - val_loss: 0.0853 - val_mean_squared_error: 0.0550\n",
      "Epoch 67/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0737 - mean_squared_error: 0.0434 - val_loss: 0.1289 - val_mean_squared_error: 0.0984\n",
      "Epoch 68/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0767 - mean_squared_error: 0.0464 - val_loss: 0.0896 - val_mean_squared_error: 0.0597\n",
      "Epoch 69/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0759 - mean_squared_error: 0.0463 - val_loss: 0.0956 - val_mean_squared_error: 0.0656\n",
      "Epoch 70/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0789 - mean_squared_error: 0.0486 - val_loss: 0.1216 - val_mean_squared_error: 0.0917\n",
      "Epoch 71/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0802 - mean_squared_error: 0.0500 - val_loss: 0.1055 - val_mean_squared_error: 0.0751\n",
      "Epoch 72/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0761 - mean_squared_error: 0.0462 - val_loss: 0.0952 - val_mean_squared_error: 0.0653\n",
      "Epoch 73/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0720 - mean_squared_error: 0.0421 - val_loss: 0.0922 - val_mean_squared_error: 0.0625\n",
      "Epoch 74/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0819 - mean_squared_error: 0.0519 - val_loss: 0.0965 - val_mean_squared_error: 0.0664\n",
      "Epoch 75/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0734 - mean_squared_error: 0.0434 - val_loss: 0.0937 - val_mean_squared_error: 0.0639\n",
      "Epoch 76/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0712 - mean_squared_error: 0.0415 - val_loss: 0.0909 - val_mean_squared_error: 0.0612\n",
      "Epoch 77/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0707 - mean_squared_error: 0.0411 - val_loss: 0.0908 - val_mean_squared_error: 0.0614\n",
      "Epoch 78/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0695 - mean_squared_error: 0.0400 - val_loss: 0.0938 - val_mean_squared_error: 0.0645\n",
      "Epoch 79/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0756 - mean_squared_error: 0.0459 - val_loss: 0.1003 - val_mean_squared_error: 0.0705\n",
      "Epoch 80/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0703 - mean_squared_error: 0.0406 - val_loss: 0.1027 - val_mean_squared_error: 0.0730\n",
      "Epoch 81/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0787 - mean_squared_error: 0.0490 - val_loss: 0.0963 - val_mean_squared_error: 0.0669\n",
      "Epoch 82/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0717 - mean_squared_error: 0.0422 - val_loss: 0.1049 - val_mean_squared_error: 0.0754\n",
      "Epoch 83/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0686 - mean_squared_error: 0.0392 - val_loss: 0.1044 - val_mean_squared_error: 0.0749\n",
      "Epoch 84/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0678 - mean_squared_error: 0.0384 - val_loss: 0.1139 - val_mean_squared_error: 0.0841\n",
      "Epoch 85/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0826 - mean_squared_error: 0.0528 - val_loss: 0.1242 - val_mean_squared_error: 0.0944\n",
      "Epoch 86/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0758 - mean_squared_error: 0.0460 - val_loss: 0.1127 - val_mean_squared_error: 0.0828\n",
      "Epoch 87/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0735 - mean_squared_error: 0.0438 - val_loss: 0.0941 - val_mean_squared_error: 0.0644\n",
      "Epoch 88/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0706 - mean_squared_error: 0.0406 - val_loss: 0.0978 - val_mean_squared_error: 0.0681\n",
      "Epoch 89/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0674 - mean_squared_error: 0.0381 - val_loss: 0.1067 - val_mean_squared_error: 0.0774\n",
      "Epoch 90/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0743 - mean_squared_error: 0.0446 - val_loss: 0.1137 - val_mean_squared_error: 0.0837\n",
      "Epoch 91/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0701 - mean_squared_error: 0.0406 - val_loss: 0.1189 - val_mean_squared_error: 0.0894\n",
      "Epoch 92/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0719 - mean_squared_error: 0.0429 - val_loss: 0.1065 - val_mean_squared_error: 0.0778\n",
      "Epoch 93/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0712 - mean_squared_error: 0.0423 - val_loss: 0.1241 - val_mean_squared_error: 0.0948\n",
      "Epoch 94/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 0.0778 - mean_squared_error: 0.0479 - val_loss: 0.0968 - val_mean_squared_error: 0.0673\n",
      "Epoch 95/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0758 - mean_squared_error: 0.0467 - val_loss: 0.1033 - val_mean_squared_error: 0.0747\n",
      "Epoch 96/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0681 - mean_squared_error: 0.0397 - val_loss: 0.1236 - val_mean_squared_error: 0.0949\n",
      "Epoch 97/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0713 - mean_squared_error: 0.0428 - val_loss: 0.1019 - val_mean_squared_error: 0.0738\n",
      "Epoch 98/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0716 - mean_squared_error: 0.0427 - val_loss: 0.0989 - val_mean_squared_error: 0.0697\n",
      "Epoch 99/100\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.0656 - mean_squared_error: 0.0366 - val_loss: 0.0966 - val_mean_squared_error: 0.0678\n",
      "Epoch 100/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1022 - mean_squared_error: 0.0728 - val_loss: 0.0883 - val_mean_squared_error: 0.0592\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluate the new model against the test set:\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'gvn': <tf.Tensor 'IteratorGetNext:0' shape=(10,) dtype=float32>, 'instcombine': <tf.Tensor 'IteratorGetNext:2' shape=(10,) dtype=float32>, 'inline': <tf.Tensor 'IteratorGetNext:1' shape=(10,) dtype=float32>, 'jump_threading': <tf.Tensor 'IteratorGetNext:5' shape=(10,) dtype=float32>, 'simplifycfg': <tf.Tensor 'IteratorGetNext:9' shape=(10,) dtype=float32>, 'sccp': <tf.Tensor 'IteratorGetNext:8' shape=(10,) dtype=float32>, 'print_used_types': <tf.Tensor 'IteratorGetNext:7' shape=(10,) dtype=float32>, 'ipsccp': <tf.Tensor 'IteratorGetNext:3' shape=(10,) dtype=float32>, 'iv_users': <tf.Tensor 'IteratorGetNext:4' shape=(10,) dtype=float32>, 'licm': <tf.Tensor 'IteratorGetNext:6' shape=(10,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 0.0815 - mean_squared_error: 0.0524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08154114335775375, 0.05242207646369934]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.007\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "label_name = \"PERF\"\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, feature_layer)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "epochs, mse = train_model(my_model, train_df, epochs, \n",
    "                          label_name, batch_size, validation_split=0.1)\n",
    "plot_the_loss_curve(epochs, mse)\n",
    "\n",
    "test_features = {name:np.array(value) for name, value in test_df.items()}\n",
    "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
